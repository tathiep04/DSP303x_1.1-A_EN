# DSP303x_1.1-A_EN
Machine Learning for Data Science

1. Types of regression model:

Simple/Multiple Linear Regression.
Simple/Multiple non-linear regression.
2. How should we find the best parameters?

Mathematic approach. 
Optimization approach.
3. Model Evaluation for Regression Models

Train/Test split.
K-fold cross-validation.

1. Classification as supervised learning

Categorizing or classifying some unknown items into a discrete set of classes.
Learn the relationship between a set of feature variables and a target variable of interest.
2. Various algorithms in Classification

K-Nearest Neighbors.
Logistic Regression.
Decision Tree.
Support Vector Machine.
3. Evaluation Metrics in Classification

Jaccard index.
F1-score: Precision, Recall.
Log Loss: The probability of a class label.
4. The Problem of Overfitting

Overfitting/Underfitting definition.
How to reduce overfitting: Reduce the number of features, regularization. 
5. Ensemble Methods

Bagging.
Boosting.
Stacking.


1. Definition of clustering

Clustering means finding clusters in a dataset, unsupervised.
The data is unlabeled and the process is unsupervised.
Applications: exploratory data analysis, summary generation or reducing the scale, outlier detection, ...


2. Various types of clustering

Partitioned-based clustering
Hierarchical clustering algorithms: Divisive and agglomerative.
Density-based clustering algorithms: Radius and minimum points, core/neighbor/outlier point.

3. k-Means

Similarity function: Cosine, Euclidean distance, Average distance.
How k-Means work in 5 steps.
More on k-Means: Accuracy, number of K.


1. Main types of recommendation systems

Content-based: Try to recommend items to users based on their profiles.
Collaborative filtering: Relationships exist between products and people's interests
Hybrid recommender systems: combine various mechanisms using ensembling methods.
In terms of implementing recommender systems: Memory-based and Model-based.
2. Collaborative filtering

Advantages: High accuracy, very effective.
Disadvantages: Data sparsity, cold start, scalability.
